#!/usr/bin/env python3

import torch
import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl 
import numpy as np
import math

from einops import rearrange, reduce
from models.gaussian_vae.gaussian_encoder import GaussianEncoder
from models.gaussian_vae.gaussian_decoder import TriplaneDecoder, ColorDecoder, ProbabilityDecoder, TransformDecoder
from input_encoder.conv_pointlite import ConvPointnetLite

class GaussianModel(pl.LightningModule):

    def __init__(self, specs):
        super().__init__()
        
        self.specs = specs
        model_specs = self.specs["GaussianModelSpecs"]
        self.hidden_dim = model_specs["hidden_dims"]
        self.latent_dim = model_specs["latent_dim"]
        self.skip_connection = model_specs.get("skip_connection", True)
        self.tanh_act = model_specs.get("tanh_act", False)
        self.pn_hidden = model_specs.get("pn_hidden_dim", 128)
        fusion_outfeatures = model_specs.get("fusion_outfeatures", 512)
        fusion_outchannels = model_specs.get("fusion_outchannels", 128)

        self.pointnet = ConvPointnetLite(
            feature_dim=self.pn_hidden,  # ğŸ”§ ä½¿ç”¨pn_hiddenè€Œä¸æ˜¯latent_dim
            input_dim=3,                 # ğŸ”§ 3Dåæ ‡ï¼Œä¸æ˜¯59
            hidden_dim=self.pn_hidden, 
            plane_resolution=64, 
            plane_types=['xy', 'xz', 'yz']
        )

        decoder_input_size = 3 + self.pn_hidden  # åæ ‡(3) + ç‚¹ç‰¹å¾(pn_hidden)

        self.color_decoder = ColorDecoder(
            latent_size=self.pn_hidden,
            hidden_dim=self.hidden_dim[-1],
            input_size=decoder_input_size,
            skip_connection=self.skip_connection,
            tanh_act=self.tanh_act
        )
        
        self.probability_decoder = ProbabilityDecoder(
            latent_size=self.pn_hidden,
            hidden_dim=self.hidden_dim[-1],
            input_size=decoder_input_size,
            skip_connection=self.skip_connection,
            tanh_act=self.tanh_act
        )
        
        self.transform_decoder = TransformDecoder(
            latent_size=self.pn_hidden,
            hidden_dim=self.hidden_dim[-1],
            input_size=decoder_input_size,
            skip_connection=self.skip_connection,
            tanh_act=self.tanh_act
        )

        self.color_decoder.train()
        self.probability_decoder.train()
        self.transform_decoder.train()

        # Gaussian VAE Encoder
        self.gaussian_encoder = GaussianEncoder(
            in_channels=fusion_outchannels,  # 768
            latent_dim=self.latent_dim,      # 512
            hidden_dims=self.hidden_dim,     # [16, 24, 40]
            kl_std=1.0,
            beta=4,
            gamma=10.,
            max_capacity=25,
            capacity_max_iteration=1e5,
            loss_type='B'
        )

        # ä½¿ç”¨ TriplaneDecoderï¼Œå°†éšå‘é‡è½¬æ¢ä¸ºä¸‰åˆ†æ”¯è¾“å‡º
        self.triplane_decoder = TriplaneDecoder(
            latent_dim=self.latent_dim, 
            grid_size=(64, 64), 
            hidden_dim=self.hidden_dim[-1]
        )
            
    def forward(self, fused_features):
        encoded_features = self.gaussian_encoder(fused_features)
        recon_x, input_data, mu, logvar, z = encoded_features

        gau_pf, gau_cf, gau_tf = self.triplane_decoder(z)

        return gau_pf, gau_cf, gau_tf

    def forward_with_plane_features(self, plane_features, query_xyz):
        """
        å½“è¾“å…¥åŒ…å« plane_features æ—¶ï¼Œ
        ç”¨ multi_modal_encoder æå–èåˆç‰¹å¾åæ˜ å°„åˆ° latent ç©ºé—´ï¼Œå†è§£ç å‡ºé¢œè‰²å’Œå‡ ä½•å˜æ¢ä¿¡æ¯ã€‚
        """
        device = plane_features.device
        query_xyz = query_xyz.to(device)
        # 1. ä»ä¸‰å¹³é¢ç‰¹å¾ä¸­æå–ç‚¹ç‰¹å¾
        point_features = self.pointnet.forward_with_plane_features(plane_features, query_xyz)
        # point_features: [B, N, pn_hidden]

        point_features = point_features.to(device)
        query_xyz = query_xyz.to(device)
        
        # 2. ğŸ”§ å…³é”®ä¿®å¤ï¼šæ‹¼æ¥åæ ‡å’Œç‰¹å¾ (ä»¿ç…§GsModel)
        combined_features = torch.cat((query_xyz, point_features), dim=-1)
        # combined_features: [B, N, 3 + pn_hidden]
        
        # 3. ä½¿ç”¨ç‹¬ç«‹è§£ç å™¨é¢„æµ‹
        pred_color = self.color_decoder(combined_features)     # [B, N, 48]
        pred_transform = self.transform_decoder(combined_features)  # [B, N, 7]
        
        return pred_color, pred_transform

    def forward_with_plane_features_pf(self, plane_features, query_xyz):
        """
        ä½¿ç”¨ plane_features æ—¶ï¼Œä¸“é—¨æå–å¯†åº¦/æ¦‚ç‡ä¿¡æ¯ã€‚
        """
        device = plane_features.device
        query_xyz = query_xyz.to(device)
        # 1. ä»ä¸‰å¹³é¢ç‰¹å¾ä¸­æå–ç‚¹ç‰¹å¾
        point_features = self.pointnet.forward_with_plane_features(plane_features, query_xyz)
        
        # 2. ğŸ”§ æ‹¼æ¥åæ ‡å’Œç‰¹å¾
        combined_features = torch.cat((query_xyz, point_features), dim=-1)
        
        # 3. å ç”¨é¢„æµ‹
        pred_occ = self.probability_decoder(combined_features)  # [B, N, 1]
        
        return pred_occ
    
    def forward_with_plane_features_occ(self, plane_features, query_xyz):
        """ğŸ”§ æ·»åŠ ï¼šä¸GsModelå…¼å®¹çš„å ç”¨é¢„æµ‹æ¥å£"""
        return self.forward_with_plane_features_pf(plane_features, query_xyz)
    
    def get_vae_loss(self, fused_features, **kwargs):
        """
        ğŸ”§ æ–°å¢ï¼šè·å–VAEæŸå¤±
        Args:
            fused_features: [B, 768, 64, 64] å¤šæ¨¡æ€èåˆç‰¹å¾
        Returns:
            dict: VAEæŸå¤±å­—å…¸
        """
        vae_outputs = self.gaussian_encoder(fused_features)
    
        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿ä¼ é€’æ­£ç¡®çš„å‚æ•°
        if 'minibatch_weight' not in kwargs:
            kwargs['minibatch_weight'] = 1.0
            
        vae_loss_dict = self.gaussian_encoder.loss_function(*vae_outputs, **kwargs)
        return vae_loss_dict
    
    def get_latent_vector(self, fused_features):
        """
        ğŸ”§ æ–°å¢ï¼šè·å–æ½œåœ¨å‘é‡
        Args:
            fused_features: [B, 768, 64, 64] å¤šæ¨¡æ€èåˆç‰¹å¾
        Returns:
            z: [B, 512] æ½œåœ¨å‘é‡
        """
        return self.gaussian_encoder.get_latent(fused_features)
    
    def decode_from_latent(self, z):
        """
        ğŸ”§ æ–°å¢ï¼šä»æ½œåœ¨å‘é‡è§£ç ä¸‰å¹³é¢ç‰¹å¾
        Args:
            z: [B, 512] æ½œåœ¨å‘é‡
        Returns:
            tuple: (gau_pf, gau_cf, gau_tf) ä¸‰å¹³é¢ç‰¹å¾
        """
        return self.triplane_decoder(z)
    
    def reconstruct(self, fused_features):
        """
        ğŸ”§ æ–°å¢ï¼šé‡æ„è¾“å…¥ç‰¹å¾
        Args:
            fused_features: [B, 768, 64, 64] å¤šæ¨¡æ€èåˆç‰¹å¾
        Returns:
            recon_x: [B, 768, 64, 64] é‡æ„ç‰¹å¾
        """
        return self.gaussian_encoder.generate(fused_features)