import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict

class VisualAlignmentLoss(nn.Module):
    """
    è®¡ç®—é¢„æµ‹ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾ä¹‹é—´çš„è§†è§‰å¯¹é½æŸå¤± (VF Loss)ã€‚
    VF Loss ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼š
    1. Marginal Cosine Similarity Loss: é¼“åŠ±é¢„æµ‹ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾åœ¨æ–¹å‘ä¸Šä¿æŒä¸€è‡´ã€‚
    2. Marginal Distance Similarity Loss: é¼“åŠ±é¢„æµ‹ç‰¹å¾å’Œç›®æ ‡ç‰¹å¾åœ¨L2è·ç¦»ä¸Šæ¥è¿‘ã€‚
    """
    
    def __init__(self, 
                 cosine_weight: float = 0.5, 
                 distance_weight: float = 0.5):
        """
        åˆå§‹åŒ–è§†è§‰å¯¹é½æŸå¤±æ¨¡å—ã€‚

        Args:
            cosine_weight (float): ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±çš„æƒé‡ã€‚
            distance_weight (float): L2è·ç¦»æŸå¤±çš„æƒé‡ã€‚
        """
        super().__init__()
        
        if cosine_weight + distance_weight != 1.0:
            print(f"Warning: Loss weights do not sum to 1.0 (cosine: {cosine_weight}, distance: {distance_weight})")
            
        self.cosine_weight = cosine_weight
        self.distance_weight = distance_weight
        
        # å®šä¹‰æœŸæœ›å¤„ç†çš„è§†è§’
        self.views = ['front', 'side', 'top']
        
    def forward(self, 
                predicted_features: Dict[str, torch.Tensor], 
                target_features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¹¶è¿”å›åŒ…å«å„é¡¹æŸå¤±çš„å­—å…¸ã€‚

        Args:
            predicted_features (Dict[str, torch.Tensor]): 
                ç”± g2f æ¨¡å—é¢„æµ‹çš„ç‰¹å¾å‘é‡å­—å…¸ã€‚
                ä¾‹å¦‚: {'front': tensor, 'side': tensor, 'top': tensor}
            
            target_features (Dict[str, torch.Tensor]): 
                ç”± 2D VFM æå–çš„ç›®æ ‡ï¼ˆçœŸå®ï¼‰ç‰¹å¾å‘é‡å­—å…¸ï¼Œä½œä¸ºç›‘ç£ä¿¡å·ã€‚
                ä¾‹å¦‚: {'front': tensor, 'side': tensor, 'top': tensor}

        Returns:
            Dict[str, torch.Tensor]: åŒ…å«æ€»æŸå¤±å’Œå„é¡¹å­æŸå¤±çš„å­—å…¸ã€‚
        """
        
        total_cosine_loss = 0.0
        total_distance_loss = 0.0
        num_valid_views = 0
        
        per_view_losses = {}

        for view in self.views:
            # ç¡®ä¿é¢„æµ‹å’Œç›®æ ‡éƒ½åŒ…å«å½“å‰è§†è§’
            if view not in predicted_features or view not in target_features:
                continue
            
            pred_feat = predicted_features[view]
            target_feat = target_features[view]
            
            # ç¡®ä¿ç‰¹å¾å‘é‡å·²ç»L2å½’ä¸€åŒ–ï¼Œè¿™å¯¹äºç¨³å®šçš„ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—å¾ˆé‡è¦
            pred_feat = F.normalize(pred_feat, p=2, dim=-1)
            target_feat = F.normalize(target_feat, p=2, dim=-1)

            # 1. è®¡ç®— Marginal Cosine Similarity Loss
            # æˆ‘ä»¬å¸Œæœ›ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¿‘1ï¼Œæ‰€ä»¥æŸå¤±æ˜¯ 1 - similarity
            cosine_loss_view = (1 - F.cosine_similarity(pred_feat, target_feat, dim=-1)).mean()
            
            # 2. è®¡ç®— Marginal Distance Similarity Loss (ä½¿ç”¨ L2 è·ç¦»)
            distance_loss_view = F.mse_loss(pred_feat, target_feat)
            
            # ç´¯åŠ æŸå¤±
            total_cosine_loss += cosine_loss_view
            total_distance_loss += distance_loss_view
            num_valid_views += 1
            
            # è®°å½•æ¯ä¸ªè§†è§’çš„å•ç‹¬æŸå¤±ï¼ˆç”¨äºè¯¦ç»†æ—¥å¿—ï¼‰
            per_view_losses[f'cosine_{view}'] = cosine_loss_view.detach()
            per_view_losses[f'distance_{view}'] = distance_loss_view.detach()

        if num_valid_views == 0:
            # å¦‚æœæ²¡æœ‰ä»»ä½•æœ‰æ•ˆçš„è§†è§’å¯¹ï¼Œè¿”å›é›¶æŸå¤±
            return {
                'vf_loss': torch.tensor(0.0, device=next(self.parameters()).device, requires_grad=True),
                'avg_cosine_loss': torch.tensor(0.0),
                'avg_distance_loss': torch.tensor(0.0)
            }

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_cosine_loss = total_cosine_loss / num_valid_views
        avg_distance_loss = total_distance_loss / num_valid_views
        
        # è®¡ç®—åŠ æƒçš„æœ€ç»ˆ VF Loss
        vf_loss = (self.cosine_weight * avg_cosine_loss) + \
                  (self.distance_weight * avg_distance_loss)
                  
        # å‡†å¤‡è¿”å›çš„æŸå¤±å­—å…¸
        loss_dict = {
            'vf_loss': vf_loss,
            'avg_cosine_loss': avg_cosine_loss.detach(),
            'avg_distance_loss': avg_distance_loss.detach()
        }
        
        # å°†æ¯ä¸ªè§†è§’çš„æŸå¤±ä¹ŸåŠ å…¥å­—å…¸
        loss_dict.update(per_view_losses)
        
        return loss_dict

# --- ä½¿ç”¨ç¤ºä¾‹ (ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º) ---
def test_visual_alignment_loss():
    print("ğŸ§ª æµ‹è¯• VisualAlignmentLoss æ¨¡å—...")
    
    # åˆå§‹åŒ–æŸå¤±å‡½æ•°
    loss_fn = VisualAlignmentLoss(cosine_weight=0.6, distance_weight=0.4)
    
    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    batch_size = 8
    feature_dim = 384 # DINOv2-small çš„ç‰¹å¾ç»´åº¦
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # æ¨¡æ‹Ÿ 2D VFM è¾“å‡ºçš„çœŸå®ç‰¹å¾
    mock_target_features = {
        'front': torch.randn(batch_size, feature_dim, device=device),
        'side': torch.randn(batch_size, feature_dim, device=device),
        'top': torch.randn(batch_size, feature_dim, device=device)
    }
    
    # æ¨¡æ‹Ÿ g2f è¾“å‡ºçš„é¢„æµ‹ç‰¹å¾ (ä¸çœŸå®ç‰¹å¾ç›¸ä¼¼ä½†æœ‰å™ªå£°)
    mock_predicted_features = {
        view: feat + torch.randn_like(feat) * 0.1 
        for view, feat in mock_target_features.items()
    }
    
    print("\næ¨¡æ‹Ÿè¾“å…¥:")
    print(f"  Batch size: {batch_size}, Feature dim: {feature_dim}")
    print(f"  é¢„æµ‹ç‰¹å¾é”®: {list(mock_predicted_features.keys())}")
    print(f"  ç›®æ ‡ç‰¹å¾é”®: {list(mock_target_features.keys())}")
    
    # è®¡ç®—æŸå¤±
    loss_dict = loss_fn(mock_predicted_features, mock_target_features)
    
    print("\nâœ… æŸå¤±è®¡ç®—æˆåŠŸï¼")
    print("è¾“å‡ºçš„æŸå¤±å­—å…¸:")
    for key, value in loss_dict.items():
        print(f"  - {key}: {value.item():.6f}")
        
    # æµ‹è¯•åªæä¾›éƒ¨åˆ†è§†è§’çš„æƒ…å†µ
    print("\næµ‹è¯•éƒ¨åˆ†è§†è§’è¾“å…¥:")
    mock_predicted_features_partial = {'front': mock_predicted_features['front']}
    mock_target_features_partial = {'front': mock_target_features['front']}
    loss_dict_partial = loss_fn(mock_predicted_features_partial, mock_target_features_partial)
    print("éƒ¨åˆ†è§†è§’æŸå¤±å­—å…¸:")
    for key, value in loss_dict_partial.items():
        print(f"  - {key}: {value.item():.6f}")


if __name__ == '__main__':
    test_visual_alignment_loss()
