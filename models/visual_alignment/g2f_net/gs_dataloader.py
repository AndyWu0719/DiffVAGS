import os
import torch
import json
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
from typing import Dict, List, Tuple
import numpy as np
import time
import pickle
from tqdm import tqdm
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, project_root)

class MultiViewGaussianDataset(Dataset):
    """é«˜æ•ˆåŠ è½½é«˜æ–¯æ•°æ®å’Œå¤šè§†è§’å›¾åƒçš„æ•°æ®é›†"""
    
    def __init__(self, 
                 gaussian_data_path: str,
                 image_data_path: str,
                 view_mapping: Dict[str, str] = None,
                 cache_path: str = "dataset_cache.pkl",
                 max_samples: int = None):
        """
        Args:
            gaussian_data_path: é«˜æ–¯æ•°æ®è·¯å¾„
            image_data_path: å›¾åƒæ•°æ®è·¯å¾„
            view_mapping: è§†è§’æ˜ å°„
            cache_path: é¢„åŠ è½½ç¼“å­˜è·¯å¾„
            max_samples: æœ€å¤§æ ·æœ¬æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        """
        self.gaussian_data_path = gaussian_data_path
        self.image_data_path = image_data_path
        
        # é»˜è®¤è§†è§’æ˜ å°„
        self.view_mapping = view_mapping or {
            'front': 'images_r0_',  # æ­£è§†å›¾
            'side': 'images_r1_',   # ä¾§è§†å›¾
            'top': 'images_r2_'     # ä¿¯è§†å›¾
        }
        
        # å›¾åƒé¢„å¤„ç†
        self.image_transform = transforms.Compose([
            transforms.Resize((518, 518)),  # å‡å°å°ºå¯¸åŠ é€Ÿå¤„ç†
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        # æ£€æŸ¥ç¼“å­˜
        if os.path.exists(cache_path):
            print(f"åŠ è½½æ•°æ®é›†ç¼“å­˜: {cache_path}")
            with open(cache_path, 'rb') as f:
                cache_data = pickle.load(f)
                self.valid_sample_ids = cache_data['sample_ids']
                self.metadata = cache_data['metadata']
        else:
            print(f"åˆ›å»ºæ•°æ®é›†ç¼“å­˜: {cache_path}")
            self.valid_sample_ids = self._get_valid_samples()
            self.metadata = self._preload_metadata()
            with open(cache_path, 'wb') as f:
                pickle.dump({
                    'sample_ids': self.valid_sample_ids,
                    'metadata': self.metadata
                }, f)
        
        # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if max_samples:
            self.valid_sample_ids = self.valid_sample_ids[:max_samples]
            self.metadata = self.metadata[:max_samples]
        
        print(f"æ‰¾åˆ° {len(self.valid_sample_ids)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
    
    def _get_valid_samples(self) -> List[str]:
        """è·å–åŒæ—¶å­˜åœ¨é«˜æ–¯æ•°æ®å’Œå›¾åƒæ•°æ®çš„æœ‰æ•ˆæ ·æœ¬"""
        valid_samples = []
        
        # éå†é«˜æ–¯æ•°æ®è·¯å¾„ä¸‹çš„æ‰€æœ‰å­ç›®å½•
        for sample_dir in os.listdir(self.gaussian_data_path):
            sample_path = os.path.join(self.gaussian_data_path, sample_dir)
            
            # ç¡®ä¿æ˜¯ç›®å½•
            if not os.path.isdir(sample_path):
                continue
                
            # æ£€æŸ¥é«˜æ–¯æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            gaussian_exists = (
                os.path.exists(os.path.join(sample_path, 'gaussian.npy')) and
                os.path.exists(os.path.join(sample_path, 'occ.npy'))
            )
            
            # æ£€æŸ¥å¯¹åº”çš„å›¾åƒæ•°æ®ç›®å½•
            image_sample_path = os.path.join(self.image_data_path, sample_dir, 'images')
            image_exists = os.path.exists(image_sample_path) and len(os.listdir(image_sample_path)) > 0
            
            # å¦‚æœä¸¤è€…éƒ½å­˜åœ¨ï¼Œåˆ™æ·»åŠ åˆ°æœ‰æ•ˆæ ·æœ¬
            if gaussian_exists and image_exists:
                valid_samples.append(sample_dir)
                
        return sorted(valid_samples, key=lambda x: int(x))
    
    def _preload_metadata(self) -> List[dict]:
        """é¢„åŠ è½½æ‰€æœ‰æ ·æœ¬çš„å…ƒæ•°æ®"""
        metadata = []
        for sample_id in tqdm(self.valid_sample_ids, desc="é¢„åŠ è½½å…ƒæ•°æ®"):
            # é«˜æ–¯æ•°æ®è·¯å¾„
            gaussian_dir = os.path.join(self.gaussian_data_path, sample_id)
            
            # å›¾åƒæ•°æ®ç›®å½•
            image_dir = os.path.join(self.image_data_path, sample_id, 'images')
            
            # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
            if os.path.exists(image_dir):
                image_files = sorted([
                    f for f in os.listdir(image_dir) 
                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))
                ])
            else:
                image_files = []
            
            # ç¡®å®šè§†è§’å›¾åƒè·¯å¾„
            view_paths = {}
            for view_name, prefix in self.view_mapping.items():
                # æ‰¾åˆ°åŒ¹é…å‰ç¼€çš„ç¬¬ä¸€ä¸ªå›¾åƒ
                match = next((f for f in image_files if f.startswith(prefix)), None)
                view_paths[view_name] = os.path.join(image_dir, match) if match else None
            
            metadata.append({
                'gaussian_dir': gaussian_dir,
                'image_dir': image_dir,
                'view_paths': view_paths
            })
        return metadata
    
    def _load_gaussian_data(self, meta: dict) -> Dict[str, torch.Tensor]:
        """åŠ è½½å¹¶é¢„å¤„ç†é«˜æ–¯æ•°æ®"""
        gaussian_file = os.path.join(meta['gaussian_dir'], 'gaussian.npy')
        occ_file = os.path.join(meta['gaussian_dir'], 'occ.npy')
        
        try:
            # åŠ è½½åŸå§‹æ•°æ® (numpy)
            gaussian = np.load(gaussian_file)  # [N, 59]
            occ = np.load(occ_file)  # [M, K]
            
            # è½¬æ¢ä¸ºtensor
            gaussian = torch.from_numpy(gaussian).float()
            occ = torch.from_numpy(occ).float()
            
            # é‡‡æ ·é«˜æ–¯ç‚¹ (16000ä¸ª)
            if gaussian.shape[0] > 16000:
                indices = torch.randperm(gaussian.shape[0])[:16000]
            else:
                indices = torch.randint(0, gaussian.shape[0], (16000,))
            sampled_gaussian = gaussian[indices]
            
            # åˆ†ç¦»xyzåæ ‡å’Œå…¶ä»–å±æ€§
            gaussian_xyz = sampled_gaussian[:, :3]  # [16000, 3]
            gaussian_attrs = sampled_gaussian[:, 3:]  # [16000, 56]
            
            # å¤„ç†ç¼©æ”¾å› å­å’Œæ—‹è½¬å››å…ƒæ•°
            gaussian_attrs[:, 49:52] = torch.exp(gaussian_attrs[:, 49:52])  # ç¼©æ”¾å› å­
            norm = torch.norm(gaussian_attrs[:, 52:56], p=2, dim=-1, keepdim=True)
            norm = torch.where(norm == 0, torch.ones_like(norm), norm)
            gaussian_attrs[:, 52:56] = gaussian_attrs[:, 52:56] / norm
            
            # é‡‡æ ·å ç”¨ç‚¹ (80000ä¸ª)
            if occ.shape[0] > 80000:
                occ_indices = torch.randperm(occ.shape[0])[:80000]
            else:
                occ_indices = torch.randint(0, occ.shape[0], (80000,))
            sampled_occ = occ[occ_indices]
            
            occ_xyz = sampled_occ[:, :3]  # [80000, 3]
            occ_attrs = sampled_occ[:, 3:]  # [80000, K-3]
            
            return {
                'gaussian_xyz': gaussian_xyz,
                'gt_gaussian': gaussian_attrs,
                'occ_xyz': occ_xyz,
                'occ': occ_attrs
            }
            
        except Exception as e:
            print(f"åŠ è½½é«˜æ–¯æ•°æ® {meta['gaussian_dir']} æ—¶å‡ºé”™: {e}")
            # è¿”å›ç©ºæ•°æ®
            return {
                'gaussian_xyz': torch.zeros(16000, 3),
                'gt_gaussian': torch.zeros(16000, 56),
                'occ_xyz': torch.zeros(80000, 3),
                'occ': torch.zeros(80000, 1)
            }
    
    def _load_view_images(self, view_paths: Dict[str, str]) -> Dict[str, torch.Tensor]:
        """åŠ è½½å¤šè§†è§’å›¾åƒ"""
        view_images = {}
        for view_name, path in view_paths.items():
            if not path or not os.path.exists(path):
                # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨å ä½ç¬¦
                view_images[f'{view_name}_image'] = torch.zeros(3, 518, 518)
                continue
            
            try:
                image = Image.open(path).convert('RGB')
                image_tensor = self.image_transform(image)
                view_images[f'{view_name}_image'] = image_tensor
            except Exception as e:
                print(f"åŠ è½½å›¾åƒ {path} æ—¶å‡ºé”™: {e}")
                view_images[f'{view_name}_image'] = torch.zeros(3, 518, 518)
        
        return view_images
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """è·å–ä¸€ä¸ªè®­ç»ƒæ ·æœ¬"""
        sample_id = self.valid_sample_ids[idx]
        meta = self.metadata[idx]
        
        # è·å–é«˜æ–¯æ•°æ®
        gaussian_data = self._load_gaussian_data(meta)
        
        # è·å–å¤šè§†è§’å›¾åƒ
        view_images = self._load_view_images(meta['view_paths'])
        
        # åˆå¹¶æ•°æ®
        combined_data = {
            'sample_id': sample_id,
            **gaussian_data,
            **view_images
        }
        
        return combined_data
    
    def __len__(self) -> int:
        return len(self.valid_sample_ids)

# æµ‹è¯•æ•°æ®é›†
def test_multiview_dataset():
    """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("ğŸ§ª æµ‹è¯•MultiViewGaussianDataset...")
    
    # ä½¿ç”¨æ‚¨æä¾›çš„å®é™…è·¯å¾„
    dataset = MultiViewGaussianDataset(
        gaussian_data_path="/media/andywu/WD6TB/WD6TB/Andy/Datasets/lightdiffgsdata/03001627/convert_data",
        image_data_path="/media/andywu/WD6TB/WD6TB/Andy/Datasets/lightdiffgsdata/03001627/training_data",
        max_samples=5  # åªæµ‹è¯•å‰5ä¸ªæ ·æœ¬
    )
    
    print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    if len(dataset) > 0:
        # æµ‹è¯•ç¬¬ä¸€ä¸ªæ ·æœ¬
        print(f"\nğŸ” æµ‹è¯•æ ·æœ¬...")
        for i in range(min(3, len(dataset))):
            sample = dataset[i]
            print(f"\næ ·æœ¬ID: {sample['sample_id']}")
            
            print(f"é«˜æ–¯æ•°æ®å½¢çŠ¶:")
            print(f"  gaussian_xyz: {sample['gaussian_xyz'].shape}")
            print(f"  gt_gaussian: {sample['gt_gaussian'].shape}")
            
            print(f"å›¾åƒæ•°æ®:")
            for view in ['front', 'side', 'top']:
                image_key = f'{view}_image'
                image_tensor = sample[image_key]
                is_blank = torch.all(image_tensor == 0)
                print(f"  {view}: {'âŒ ç©ºç™½å›¾åƒ' if is_blank else 'âœ… æœ‰æ•ˆå›¾åƒ'} ({image_tensor.shape})")

if __name__ == "__main__":
    test_multiview_dataset()