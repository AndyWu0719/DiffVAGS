#!/usr/bin/env python3
import os
import json
import torch
import warnings
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from torch.utils.data import DataLoader, Dataset
from argparse import ArgumentParser

from models.combine_model import CombinedModel
from dataloader.modulation_loader import ModulationLoader
from dataloader.multimodal_loader import MultiModalDataset 
from input_encoder.multimodal_encoder import MultiModalEncoder
from input_encoder.text_encoder import TextEncoder
from input_encoder.image_encoder import ImageEncoder
from dataloader.multimodal_loader import MultiModalDataLoader


def print_config_summary(specs):
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡: {specs['training_task']}")
    print(f"ğŸ“Š é…ç½®æ‘˜è¦:")
    
    # ğŸ”§ å®‰å…¨è®¿é—®é…ç½®å‚æ•°
    try:
        print(f"  - VAEæ½œåœ¨ç»´åº¦: {specs['VAESpecs']['encoder']['latent_dim']}")
    except KeyError:
        print(f"  - VAEæ½œåœ¨ç»´åº¦: é…ç½®ç¼ºå¤±")
    
    try:
        print(f"  - å¤šæ¨¡æ€è¾“å‡ºé€šé“: {specs['MultiModalEncoderSpecs']['fusion']['output_channels']}")
    except KeyError:
        print(f"  - å¤šæ¨¡æ€è¾“å‡ºé€šé“: é…ç½®ç¼ºå¤±")
    
    try:
        print(f"  - è®­ç»ƒè½®æ•°: {specs['TrainingSpecs']['num_epochs']}")
    except KeyError:
        # å…¼å®¹æ—§é…ç½®
        print(f"  - è®­ç»ƒè½®æ•°: {specs.get('num_epochs', 'é…ç½®ç¼ºå¤±')}")
    
    # VA-VAEé…ç½®æ£€æŸ¥
    if specs.get('VAVAESpecs', {}).get('enable', False):
        try:
            visual_type = specs['VAVAESpecs']['visual_model']['type']
            language_type = specs['VAVAESpecs']['language_model']['type']
            print(f"  - ä½¿ç”¨VA-VAEçº¦æŸ: {visual_type} + {language_type}")
        except KeyError:
            print(f"  - VA-VAEé…ç½®ä¸å®Œæ•´")


def create_multimodal_dataloader(specs):
    """åˆ›å»ºå¤šæ¨¡æ€æ•°æ®åŠ è½½å™¨"""
    # ğŸ”§ ä»é…ç½®ä¸­è·å–è·¯å¾„ï¼Œæä¾›é»˜è®¤å€¼
    data_path = specs.get("Text_Image_Data_path", "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1")
    caption_path = os.path.join(data_path, "texts", "captions.txt")
    image_path = os.path.join(data_path, "images")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(caption_path):
        print(f"âš ï¸  è­¦å‘Š: æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {caption_path}")
        caption_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1/texts/captions.txt"
    
    if not os.path.exists(image_path):
        print(f"âš ï¸  è­¦å‘Š: å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_path}")
        image_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1/images"
    
    print(f"ğŸ“ æ•°æ®è·¯å¾„:")
    print(f"  - æ–‡æœ¬: {caption_path}")
    print(f"  - å›¾åƒ: {image_path}")
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = MultiModalDataset(caption_file=caption_path, image_dir=image_path)
    
    # ğŸ”§ ä»ç»Ÿä¸€é…ç½®è·å–å‚æ•°
    try:
        multimodal_specs = specs['MultiModalEncoderSpecs']
        fusion_specs = multimodal_specs['fusion']
        
        output_channels = fusion_specs['output_channels']
        output_features = fusion_specs['output_features'] 
        output_resolution = fusion_specs['output_resolution']
        
    except KeyError as e:
        print(f"âŒ å¤šæ¨¡æ€ç¼–ç å™¨é…ç½®ç¼ºå¤±: {e}")
        # ğŸ”§ ä½¿ç”¨å…¼å®¹çš„æ—§é…ç½®
        output_channels = specs.get("GaussianModelSpecs1", {}).get("pn_hidden_dim", 128)
        output_features = 512
        output_resolution = 64
        print(f"ğŸ”„ ä½¿ç”¨å…¼å®¹é…ç½®: channels={output_channels}, features={output_features}")
    
    # åˆ›å»ºç¼–ç å™¨
    text_encoder = TextEncoder()
    image_encoder = ImageEncoder()
    
    encoder = MultiModalEncoder(
        text_encoder=text_encoder,
        image_encoder=image_encoder,
        output_channels=output_channels,
        output_features=output_features,
        output_resolution=output_resolution,
        freeze_encoders=True
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    fused_dataset = MultiModalDataLoader(train_dataset, encoder, device)
    
    return fused_dataset


def create_trainer(specs, args, callbacks):
    """åˆ›å»ºè®­ç»ƒå™¨"""
    # ğŸ”§ å®‰å…¨è·å–è®­ç»ƒå‚æ•°
    try:
        num_epochs = specs['TrainingSpecs']['num_epochs']
    except KeyError:
        num_epochs = specs.get('num_epochs', 200)  # å…¼å®¹æ—§é…ç½®
    
    try:
        log_freq = specs['TrainingSpecs']['log_freq'] 
    except KeyError:
        log_freq = specs.get('log_freq', 10)  # å…¼å®¹æ—§é…ç½®
    
    print(f"ğŸ¯ è®­ç»ƒå™¨é…ç½®: epochs={num_epochs}, log_freq={log_freq}")
    
    trainer = pl.Trainer(
        accelerator='gpu', 
        devices=1, 
        precision='16-mixed',
        max_epochs=num_epochs,
        callbacks=callbacks,
        log_every_n_steps=10,
        default_root_dir=os.path.join("tensorboard_logs", args.exp_dir),
        # å†…å­˜ä¼˜åŒ–é…ç½®
        gradient_clip_val=1.0,
        accumulate_grad_batches=1,
        enable_progress_bar=True,
        enable_model_summary=False,
        enable_checkpointing=True,
        num_sanity_val_steps=0,
        limit_train_batches=1.0,
        reload_dataloaders_every_n_epochs=0,
    )
    
    return trainer


def train(specs, args):
    """ç»Ÿä¸€çš„è®­ç»ƒå‡½æ•°"""
    print_config_summary(specs)
    
    # ğŸ”§ æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ•°æ®åŠ è½½å™¨
    if specs['training_task'] == 'diffusion':
        print("ğŸ“Š ä½¿ç”¨æ‰©æ•£ä»»åŠ¡æ•°æ®åŠ è½½å™¨")
        train_dataset = ModulationLoader(specs["Data_path"], gs_path=specs.get("gs_path", None))
        fused_dataset = train_dataset
    else:
        print("ğŸ“Š ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®åŠ è½½å™¨")
        fused_dataset = create_multimodal_dataloader(specs)
    
    print("ğŸ”„ Loading dataset...")
    
    # ğŸ”§ ä»é…ç½®è·å–æ•°æ®åŠ è½½å™¨å‚æ•°
    try:
        dataloader_specs = specs.get('DataLoaderSpecs', {})
        batch_size = dataloader_specs.get('batch_size', 1)
        num_workers = dataloader_specs.get('num_workers', 0)
        shuffle = dataloader_specs.get('shuffle', True)
        pin_memory = dataloader_specs.get('pin_memory', False)
    except:
        # é»˜è®¤é…ç½®
        batch_size, num_workers, shuffle, pin_memory = 1, 0, True, False
    
    train_dataloader = DataLoader(
        fused_dataset,
        batch_size=batch_size,
        num_workers=num_workers,
        drop_last=True,
        shuffle=shuffle,
        pin_memory=pin_memory,
        persistent_workers=False,
    )
    
    # ğŸ”§ è®¾ç½®å›è°ƒ - å…¼å®¹æ–°æ—§é…ç½®
    try:
        log_freq = specs['TrainingSpecs']['log_freq']
    except KeyError:
        log_freq = specs.get('log_freq', 50)
    
    checkpoint_callback = ModelCheckpoint(
        dirpath=args.exp_dir, 
        filename='{epoch}', 
        save_top_k=3, 
        save_last=False, 
        every_n_epochs=log_freq,
        monitor='train/total_loss',      # ğŸ”§ ä¿®æ­£ç›‘æ§æŒ‡æ ‡
        mode='min',
        auto_insert_metric_name=False,
        save_on_train_epoch_end=True,
        save_weights_only=True,
    )
    
    lr_monitor = LearningRateMonitor(logging_interval='epoch')
    callbacks = [checkpoint_callback, lr_monitor]
    
    # æ„é€ æ¨¡å‹
    print("ğŸ”§ åˆå§‹åŒ–æ¨¡å‹...")
    model = CombinedModel(specs)
    
    # Resume å¤„ç†é€»è¾‘
    resume_ckpt = None
    if args.resume == 'finetune':
        print("ğŸ”„ å¾®è°ƒæ¨¡å¼ï¼šåŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹...")
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                model = model.load_from_checkpoint(
                    specs["modulation_ckpt_path"], 
                    specs=specs, 
                    strict=False
                )
                ckpt = torch.load(specs["diffusion_ckpt_path"], map_location="cpu")
                new_state_dict = {k.replace("diffusion_model.", ""): v for k, v in ckpt['state_dict'].items()}
                model.diffusion_model.load_state_dict(new_state_dict)
            resume_ckpt = None
        except Exception as e:
            print(f"âš ï¸  å¾®è°ƒåŠ è½½å¤±è´¥: {e}")
            
    elif args.resume is not None:
        ckpt_name = "last.ckpt" if args.resume == "last" else f"epoch={args.resume}.ckpt"
        resume_ckpt = os.path.join(args.exp_dir, ckpt_name)
        if os.path.exists(resume_ckpt):
            print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤: {resume_ckpt}")
        else:
            print(f"âš ï¸  æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {resume_ckpt}")
            resume_ckpt = None
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = create_trainer(specs, args, callbacks)
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    try:
        trainer.fit(model=model, train_dataloaders=train_dataloader, ckpt_path=resume_ckpt)
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        raise


if __name__ == "__main__":
    import torch.multiprocessing as mp
    mp.set_start_method("spawn", force=True)

    parser = ArgumentParser(description="Training script for LightDiffGS")
    parser.add_argument("--exp_dir", "-e", required=True,
                        help="Path to experiment directory containing specs.json")
    parser.add_argument("--resume", "-r", default=None,
                        help="Resume training: specify epoch, 'last', or 'finetune'")
    parser.add_argument("--batch_size", "-b", type=int, default=None,
                        help="Override batch size (optional)")
    parser.add_argument("--workers", "-w", type=int, default=None,
                        help="Override num workers (optional)")
    
    args = parser.parse_args()
    
    # ğŸ”§ æ£€æŸ¥é…ç½®æ–‡ä»¶
    specs_path = os.path.join(args.exp_dir, "specs.json")
    if not os.path.exists(specs_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {specs_path}")
    
    with open(specs_path, "r") as f:
        specs = json.load(f)
    
    # ğŸ”§ å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.batch_size is not None:
        specs.setdefault('DataLoaderSpecs', {})['batch_size'] = args.batch_size
    if args.workers is not None:
        specs.setdefault('DataLoaderSpecs', {})['num_workers'] = args.workers
    
    print("=" * 60)
    print("ğŸ¯ LightDiffGS Training")
    print("=" * 60)
    print("Experiment Description:", specs.get("Description", "No Description"))
    print("=" * 60)
    
    warnings.simplefilter("ignore")
    train(specs, args)