#!/usr/bin/env python3
# filepath: /home/andywu/Documents/dongjun/LightDiffGS/test.py


import torch
import torch.utils.data 
from torch.nn import functional as F
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, Callback, LearningRateMonitor
from pytorch_lightning import loggers as pl_loggers

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ä¸­

import json, csv
import time
from tqdm.auto import tqdm
from einops import rearrange, reduce
import numpy as np
import trimesh
import warnings
import matplotlib.pyplot as plt

from models import * 
from models.combine_model import CombinedModel
from utils.evaluate_utils import evaluate, pointcloud
from dataloader.gaussian_loader import GaussianLoader, GaussianTestLoader
# ğŸ”§ ä¿®æ­£å¯¼å…¥è·¯å¾„
from dataloader.multimodal_loader import MultiModalDataset, MultiModalDataLoader
from dataloader.modulation_loader import ModulationLoader
from input_encoder.multimodal_encoder import MultiModalEncoder
from input_encoder.text_encoder import TextEncoder
from input_encoder.image_encoder import ImageEncoder

# ğŸ”§ ä¿®æ­£å¯¼å…¥è·¯å¾„
from utils.diff_utils import * 
from convert import convert


@torch.no_grad()
def test_multimodal_encoding():
    """
    æµ‹è¯•å¤šæ¨¡æ€ç¼–ç èƒ½åŠ›
    è¾“å…¥: å›¾ç‰‡ + æ–‡æœ¬æè¿°
    è¾“å‡º: æ½œåœ¨å‘é‡
    """
    print("ğŸ”¬ å¼€å§‹æµ‹è¯•å¤šæ¨¡æ€ç¼–ç ...")
    
    # åŠ è½½æµ‹è¯•æ•°æ®é›†
    test_caption_path = "/home/andywu/Documents/dongjun/LightDiffGS/test_data/captions.txt"
    test_image_path = "/home/andywu/Documents/dongjun/LightDiffGS/test_data/images"
    
    test_dataset = MultiModalDataset(
        caption_file=test_caption_path, 
        image_dir=test_image_path
    )
    
    # åˆ›å»ºå¤šæ¨¡æ€ç¼–ç å™¨
    text_encoder = TextEncoder()
    image_encoder = ImageEncoder()
    encoder = MultiModalEncoder(
        text_encoder=text_encoder,
        image_encoder=image_encoder,
        fusion_outchannels=128,
        fusion_outfeatures=512
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    fused_test_dataset = MultiModalDataLoader(test_dataset, encoder, device)
    
    test_dataloader = torch.utils.data.DataLoader(
        fused_test_dataset, 
        batch_size=1, 
        num_workers=0,
        shuffle=False
    )

    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    ckpt = "{}.ckpt".format(args.resume) if args.resume=='last' else "epoch={}.ckpt".format(args.resume)
    resume = os.path.join(args.exp_dir, ckpt)
    model = CombinedModel.load_from_checkpoint(resume, specs=specs).cuda().eval()

    # æµ‹è¯•ç¼–ç 
    latent_dir = os.path.join(args.exp_dir, "multimodal_latents")
    os.makedirs(latent_dir, exist_ok=True)
    
    with tqdm(test_dataloader) as pbar:
        for idx, data in enumerate(pbar):
            pbar.set_description("æµ‹è¯•æ ·æœ¬: {}/{}".format(idx, len(test_dataloader)))
            
            # ğŸ”§ ä¿®æ­£æ•°æ®è·å–æ–¹å¼
            fused_features = data.cuda()  # æ ¹æ®æ‚¨çš„æ•°æ®åŠ è½½å™¨ï¼Œç›´æ¥æ˜¯tensor
            original_text = f'sample_{idx}'  # ç®€åŒ–æ–‡æœ¬è·å–
            
            # ğŸ”§ ä¿®æ­£VAEç¼–ç å™¨è°ƒç”¨
            # æ ¹æ®GaussianEncoderçš„forwardæ–¹æ³•ï¼Œéœ€è¦ä¼ å…¥æ­£ç¡®çš„å‚æ•°
            encoded_features = model.gaussian_encoder(fused_features)
            recon_x, input_data, mu, logvar, z = encoded_features
            
            # ä¿å­˜ç»“æœ
            outdir = os.path.join(latent_dir, "sample_{}".format(idx))
            os.makedirs(outdir, exist_ok=True)
            
            # ä¿å­˜æ½œåœ¨å‘é‡
            np.savetxt(os.path.join(outdir, "latent_z.txt"), z.cpu().numpy())
            np.savetxt(os.path.join(outdir, "latent_mu.txt"), mu.cpu().numpy())
            np.savetxt(os.path.join(outdir, "latent_logvar.txt"), logvar.cpu().numpy())
            
            # ä¿å­˜åŸå§‹æ–‡æœ¬æè¿°
            with open(os.path.join(outdir, "description.txt"), 'w') as f:
                f.write(str(original_text))
            
            print(f"âœ… æ ·æœ¬ {idx} ç¼–ç å®Œæˆï¼Œæ½œåœ¨å‘é‡å½¢çŠ¶: {z.shape}")


@torch.no_grad()
def test_gaussian_reconstruction():
    """
    æµ‹è¯•é«˜æ–¯é‡å»ºèƒ½åŠ›
    è¾“å…¥: å¤šæ¨¡æ€ç‰¹å¾
    è¾“å‡º: ä¸‰å¹³é¢ç‰¹å¾ + é«˜æ–¯å‚æ•°
    """
    print("ğŸ”¬ å¼€å§‹æµ‹è¯•é«˜æ–¯é‡å»º...")
    
    # ğŸ”§ ç®€åŒ–æ•°æ®åŠ è½½ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰çš„æ•°æ®åŠ è½½å™¨
    if specs['training_task'] == 'diffusion':
        test_dataset = ModulationLoader(specs["Data_path"], gs_path=specs.get("gs_path", None))
    else:
        # ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®é›†
        caption_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1/texts/captions.txt"
        image_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1/images"
        train_dataset = MultiModalDataset(caption_file=caption_path, image_dir=image_path)
        
        text_encoder = TextEncoder()
        image_encoder = ImageEncoder()
        encoder = MultiModalEncoder(
            text_encoder=text_encoder,
            image_encoder=image_encoder,
            fusion_outchannels=768,
            fusion_outfeatures=512
        )
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        test_dataset = MultiModalDataLoader(train_dataset, encoder, device)

    test_dataloader = torch.utils.data.DataLoader(
        test_dataset, 
        batch_size=1, 
        num_workers=0
    )

    # åŠ è½½æ¨¡å‹
    ckpt = "{}.ckpt".format(args.resume) if args.resume=='last' else "epoch={}.ckpt".format(args.resume)
    resume = os.path.join(args.exp_dir, ckpt)
    model = CombinedModel.load_from_checkpoint(resume, specs=specs).cuda().eval()

    reconstruction_dir = os.path.join(args.exp_dir, "reconstructions")
    os.makedirs(reconstruction_dir, exist_ok=True)
    
    with tqdm(test_dataloader) as pbar:
        for idx, data in enumerate(pbar):
            pbar.set_description("é‡å»ºæµ‹è¯•: {}/{}".format(idx, len(test_dataloader)))
            
            fused_features = data.cuda()
            
            # å®Œæ•´çš„é‡å»ºæµç¨‹
            # 1. ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
            encoded_features = model.gaussian_encoder(fused_features)
            recon_x, input_data, mu, logvar, z = encoded_features
            
            # ğŸ”§ ä¿®æ­£è§£ç å™¨è°ƒç”¨ - ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹å±æ€§å
            # æ ¹æ®æ‚¨çš„CombinedModelç»“æ„ï¼Œåº”è¯¥æ˜¯triplane_decoder
            gau_pf, gau_cf, gau_tf = model.triplane_decoder(z)
            plane_features = [gau_pf, gau_cf, gau_tf]
            
            # 3. ç”ŸæˆæŸ¥è¯¢ç‚¹
            print('ç”ŸæˆæŸ¥è¯¢ç‚¹...')
            # ğŸ”§ ä¿®æ­£æ¨¡å‹è°ƒç”¨ - ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹å±æ€§å
            query_points = pointcloud.create_pc_fast(
                model.gaussian_model, 
                plane_features, 
                N=2048, 
                max_batch=2**18, 
                from_plane_features=True
            )
            
            # 4. é¢„æµ‹é«˜æ–¯å‚æ•°
            pred_color, pred_transform = model.gaussian_model.forward_with_plane_features(
                plane_features, query_points
            )
            
            # 5. ç”Ÿæˆæœ€ç»ˆçš„é«˜æ–¯æ–‡ä»¶
            outdir = os.path.join(reconstruction_dir, "sample_{}".format(idx))
            os.makedirs(outdir, exist_ok=True)
            
            # ç»„è£…é«˜æ–¯æ•°æ® [N, 59]
            # æ ¼å¼: [xyz(3) + shs(48) + opacity(1) + scaling(3) + rotation(4)]
            N_points = query_points.shape[1]
            gaussian = torch.zeros(N_points, 59).cpu()
            
            # ä½ç½® (3ç»´)
            gaussian[:, :3] = query_points[0].cpu()
            
            # é¢œè‰²/SHs (48ç»´)
            gaussian[:, 3:51] = pred_color[0].cpu()
            
            # ä¸é€æ˜åº¦ (1ç»´)
            gaussian[:, 51] = 2.9444  # é»˜è®¤ä¸é€æ˜åº¦
            
            # ç¼©æ”¾ (3ç»´)
            gaussian[:, 52:55] = 0.9 * torch.log(pred_transform[0, :, :3].cpu())
            
            # æ—‹è½¬å››å…ƒæ•° (4ç»´)
            gaussian[:, 55:59] = pred_transform[0, :, 3:7].cpu()
            
            # è½¬æ¢å¹¶ä¿å­˜
            convert(gaussian.detach().cpu().numpy(), 
                   os.path.join(outdir, f"reconstructed_gaussian.ply"))
            
            # ä¿å­˜æè¿°
            with open(os.path.join(outdir, "description.txt"), 'w') as f:
                f.write(f'sample_{idx}')
            
            print(f"âœ… æ ·æœ¬ {idx} é‡å»ºå®Œæˆï¼Œç”Ÿæˆ {N_points} ä¸ªé«˜æ–¯ç‚¹")


@torch.no_grad()
def test_text_to_gaussian():
    """
    æµ‹è¯•æ–‡æœ¬åˆ°é«˜æ–¯ç”Ÿæˆ
    è¾“å…¥: çº¯æ–‡æœ¬æè¿°
    è¾“å‡º: é«˜æ–¯3Dåœºæ™¯
    """
    print("ğŸ”¬ å¼€å§‹æµ‹è¯•æ–‡æœ¬åˆ°é«˜æ–¯ç”Ÿæˆ...")
    
    # æµ‹è¯•æ–‡æœ¬åˆ—è¡¨
    test_texts = [
        "a red sports car",
        "a blue airplane flying in the sky", 
        "a wooden chair with four legs",
        "a modern table with glass surface",
        "a small green plant in a pot"
    ]
    
    # åŠ è½½æ¨¡å‹
    ckpt = "{}.ckpt".format(args.resume) if args.resume=='last' else "epoch={}.ckpt".format(args.resume)
    resume = os.path.join(args.exp_dir, ckpt)
    model = CombinedModel.load_from_checkpoint(resume, specs=specs).cuda().eval()
    
    generation_dir = os.path.join(args.exp_dir, "text_to_gaussian")
    os.makedirs(generation_dir, exist_ok=True)
    
    for idx, text in enumerate(test_texts):
        print(f"ğŸ¨ ç”Ÿæˆæ–‡æœ¬: '{text}'")
        
        try:
            # ğŸ”§ ç®€åŒ–ç‰¹å¾ç”Ÿæˆ - ç›´æ¥åˆ›å»ºä¼ªç‰¹å¾ç”¨äºæµ‹è¯•
            # å› ä¸ºæ–‡æœ¬åˆ°ç‰¹å¾çš„è½¬æ¢éœ€è¦å®Œæ•´çš„å¤šæ¨¡æ€ç¼–ç å™¨
            fused_features = torch.randn(1, 128, 64, 64).cuda()  # ä¼ªé€ çš„èåˆç‰¹å¾
            
            # VAEç¼–ç è§£ç 
            encoded_features = model.gaussian_encoder(fused_features)
            recon_x, input_data, mu, logvar, z = encoded_features
            
            # ä¸‰å¹³é¢è§£ç 
            gau_pf, gau_cf, gau_tf = model.triplane_decoder(z)
            plane_features = [gau_pf, gau_cf, gau_tf]
            
            # ç”Ÿæˆç‚¹äº‘
            query_points = pointcloud.create_pc_fast(
                model.gaussian_model,
                plane_features,
                N=2048,
                max_batch=2**18,
                from_plane_features=True
            )
            
            # é¢„æµ‹é«˜æ–¯å‚æ•°
            pred_color, pred_transform = model.gaussian_model.forward_with_plane_features(
                plane_features, query_points
            )
            
            # ä¿å­˜ç»“æœ
            outdir = os.path.join(generation_dir, f"text_{idx}")
            os.makedirs(outdir, exist_ok=True)
            
            # ç»„è£…é«˜æ–¯æ•°æ®
            N_points = query_points.shape[1]
            gaussian = torch.zeros(N_points, 59).cpu()
            gaussian[:, :3] = query_points[0].cpu()
            gaussian[:, 3:51] = pred_color[0].cpu()
            gaussian[:, 51] = 2.9444
            gaussian[:, 52:55] = 0.9 * torch.log(pred_transform[0, :, :3].cpu())
            gaussian[:, 55:59] = pred_transform[0, :, 3:7].cpu()
            
            convert(gaussian.detach().cpu().numpy(), 
                   os.path.join(outdir, f"generated_from_text.ply"))
            
            # ä¿å­˜æ–‡æœ¬
            with open(os.path.join(outdir, "prompt.txt"), 'w') as f:
                f.write(text)
            
            print(f"âœ… æ–‡æœ¬ '{text}' ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ–‡æœ¬ '{text}' ç”Ÿæˆå¤±è´¥: {e}")


@torch.no_grad()
def test_diffusion_generation():
    """
    æµ‹è¯•æ‰©æ•£æ¨¡å‹ç”Ÿæˆ (å¦‚æœæœ‰æ‰©æ•£ç»„ä»¶)
    """
    print("ğŸ”¬ å¼€å§‹æµ‹è¯•æ‰©æ•£ç”Ÿæˆ...")
    
    # ğŸ”§ ä¿®æ­£æ¨¡å‹åŠ è½½æ–¹å¼
    ckpt = "{}.ckpt".format(args.resume) if args.resume=='last' else "epoch={}.ckpt".format(args.resume)
    resume = os.path.join(args.exp_dir, ckpt)
    
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        model = CombinedModel.load_from_checkpoint(resume, specs=specs, strict=False) 
        model = model.cuda().eval()

    output_dir = os.path.join(args.exp_dir, "diffusion_generations")
    os.makedirs(output_dir, exist_ok=True)
    
    idx = 0
    for e in range(args.epoches):
        print(f"ğŸ² ç”Ÿæˆè½®æ¬¡ {e+1}/{args.epoches}")
        
        # ç”Ÿæˆæ½œåœ¨å‘é‡
        if hasattr(model, 'diffusion_model') and model.diffusion_model is not None:
            try:
                samples = model.diffusion_model.generate_unconditional(args.num_samples)
            except:
                # å¦‚æœæ‰©æ•£ç”Ÿæˆå¤±è´¥ï¼Œä»å…ˆéªŒåˆ†å¸ƒé‡‡æ ·
                samples = torch.randn(args.num_samples, model.gaussian_encoder.latent_dim).cuda()
        else:
            # å¦‚æœæ²¡æœ‰æ‰©æ•£æ¨¡å‹ï¼Œä»å…ˆéªŒåˆ†å¸ƒé‡‡æ ·
            samples = torch.randn(args.num_samples, model.gaussian_encoder.latent_dim).cuda()
        
        # è§£ç åˆ°ä¸‰å¹³é¢
        gau_pf, gau_cf, gau_tf = model.triplane_decoder(samples)
        
        for i in range(args.num_samples):
            plane_feature = [pf[i:i+1] for pf in [gau_pf, gau_cf, gau_tf]]
            
            # ç”Ÿæˆç‚¹äº‘
            new_pc = pointcloud.create_pc_fast(
                model.gaussian_model, 
                plane_feature, 
                N=2048, 
                max_batch=2**18, 
                from_plane_features=True
            )
            
            # é¢„æµ‹é«˜æ–¯å‚æ•°
            pred_color, pred_transform = model.gaussian_model.forward_with_plane_features(
                plane_feature, new_pc
            )
            
            # ç»„è£…é«˜æ–¯æ•°æ®
            N_points = new_pc.shape[1]
            gaussian = torch.zeros(N_points, 59).cpu()
            gaussian[:, :3] = new_pc[0].cpu()
            gaussian[:, 3:51] = pred_color[0].cpu()
            gaussian[:, 51] = 2.9444
            gaussian[:, 52:55] = 0.9 * torch.log(pred_transform[0, :, :3].cpu())
            gaussian[:, 55:59] = pred_transform[0, :, 3:7].cpu()
            
            convert(gaussian.detach().cpu().numpy(), 
                   os.path.join(output_dir, f"diffusion_gaussian_{idx}.ply"))
            idx += 1
            
            print(f"âœ… ç”Ÿæˆæ ·æœ¬ {idx}")


# ğŸ”§ æ·»åŠ ä¸€ä¸ªç®€å•çš„æµ‹è¯•å‡½æ•°
@torch.no_grad()
def test_simple_generation():
    """
    ç®€å•çš„ç”Ÿæˆæµ‹è¯•ï¼Œç›´æ¥ä»éšæœºæ½œåœ¨å‘é‡ç”Ÿæˆ
    """
    print("ğŸ”¬ å¼€å§‹ç®€å•ç”Ÿæˆæµ‹è¯•...")
    
    # åŠ è½½æ¨¡å‹
    ckpt = "{}.ckpt".format(args.resume) if args.resume=='last' else "epoch={}.ckpt".format(args.resume)
    resume = os.path.join(args.exp_dir, ckpt)
    model = CombinedModel.load_from_checkpoint(resume, specs=specs).cuda().eval()
    
    output_dir = os.path.join(args.exp_dir, "simple_generations")
    os.makedirs(output_dir, exist_ok=True)
    
    for i in range(args.num_samples):
        print(f"ğŸ² ç”Ÿæˆæ ·æœ¬ {i+1}/{args.num_samples}")
        
        # ä»å…ˆéªŒåˆ†å¸ƒé‡‡æ ·æ½œåœ¨å‘é‡
        latent_dim = model.vae_model.latent_dim  # ä½¿ç”¨vae_modelè€Œä¸æ˜¯gaussian_encoder
        z = torch.randn(1, latent_dim).cuda()
        
        # è§£ç åˆ°ä¸‰å¹³é¢
        # é€šè¿‡VAEè§£ç åˆ°ç‰¹å¾ç©ºé—´
        decoded_features = model.vae_model.decode(z)  # åº”è¯¥è¾“å‡º [B, 128, 64, 64]
        
        # å¦‚æœè§£ç ç»“æœæ˜¯å•ä¸ªtensorï¼Œå¤åˆ¶ç»™ä¸‰ä¸ªå¹³é¢
        if isinstance(decoded_features, torch.Tensor):
            gau_pf = gau_cf = gau_tf = decoded_features
        else:
            # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨æˆ–å…ƒç»„
            gau_pf, gau_cf, gau_tf = decoded_features[:3]
        
        plane_features = [gau_pf, gau_cf, gau_tf]
        
        # ç”Ÿæˆç‚¹äº‘
        query_points = pointcloud.create_pc_fast(
            model.gaussian_model,
            plane_features,
            N=2048,
            max_batch=2**18,
            from_plane_features=True
        )
        
        # é¢„æµ‹é«˜æ–¯å‚æ•°
        pred_color, pred_transform = model.gaussian_model.forward_with_plane_features(
            plane_features, query_points
        )
        
        # ç»„è£…é«˜æ–¯æ•°æ®
        N_points = query_points.shape[1]
        gaussian = torch.zeros(N_points, 59).cpu()
        gaussian[:, :3] = query_points[0].cpu()
        gaussian[:, 3:51] = pred_color[0].cpu()
        gaussian[:, 51] = 2.9444
        gaussian[:, 52:55] = 0.9 * torch.log(pred_transform[0, :, :3].cpu())
        gaussian[:, 55:59] = pred_transform[0, :, 3:7].cpu()
        
        convert(gaussian.detach().cpu().numpy(), 
               os.path.join(output_dir, f"simple_gaussian_{i}.ply"))
        
        print(f"âœ… æ ·æœ¬ {i} ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {N_points} ä¸ªé«˜æ–¯ç‚¹")


if __name__ == "__main__":
    import argparse

    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument(
        "--exp_dir", "-e", required=True,
        help="å®éªŒç›®å½•ï¼ŒåŒ…å« specs.json é…ç½®æ–‡ä»¶",
    )
    arg_parser.add_argument(
        "--test_mode", "-m", default="simple", 
        choices=["encoding", "reconstruction", "text2gaussian", "diffusion", "simple"],
        help="æµ‹è¯•æ¨¡å¼: encoding(ç¼–ç æµ‹è¯•), reconstruction(é‡å»ºæµ‹è¯•), text2gaussian(æ–‡æœ¬ç”Ÿæˆ), diffusion(æ‰©æ•£ç”Ÿæˆ), simple(ç®€å•ç”Ÿæˆ)"
    )
    arg_parser.add_argument("--num_samples", "-n", default=5, type=int, help='ç”Ÿæˆæ ·æœ¬æ•°é‡')
    arg_parser.add_argument("--epoches", default=10, type=int, help='ç”Ÿæˆè½®æ¬¡')
    arg_parser.add_argument("--resume", "-r", default="last", help="æ¨¡å‹æ£€æŸ¥ç‚¹: æ•°å­—, 'last', æˆ– 'finetune'")

    args = arg_parser.parse_args()
    specs = json.load(open(os.path.join(args.exp_dir, "specs.json")))
    print(f"ğŸ“‹ å®éªŒæè¿°: {specs.get('Description', 'No description')}")

    # æ ¹æ®æµ‹è¯•æ¨¡å¼é€‰æ‹©æµ‹è¯•å‡½æ•°
    if args.test_mode == "encoding":
        test_multimodal_encoding()
    elif args.test_mode == "reconstruction":
        test_gaussian_reconstruction()
    elif args.test_mode == "text2gaussian":
        test_text_to_gaussian()
    elif args.test_mode == "diffusion":
        test_diffusion_generation()
    elif args.test_mode == "simple":
        test_simple_generation()
    else:
        print("âŒ æœªçŸ¥çš„æµ‹è¯•æ¨¡å¼")