import sys
import os
import torch
import numpy as np
import torchvision.transforms as transforms


sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from input_encoder.text_encoder import TextEncoder
from input_encoder.image_encoder import ImageEncoder
from input_encoder.multimodal_encoder import MultiModalEncoder
from dataloader.gaussian_loader import GaussianLoader
from dataloader.multimodal_loader import MultiModalDataLoader, MultiModalDataset
from models.gaussian_vae.gaussian_encoder import GaussianEncoder
from models.gaussian_vae.gaussian_decoder import TriplaneDecoder
from models.gaussian_vae.gaussian_model import GaussianModel

def print_tensor_info(name, tensor):
    """æ‰“å°å¼ é‡ä¿¡æ¯"""
    if isinstance(tensor, torch.Tensor):
        print(f"{name:30s} | Shape: {str(tensor.shape):20s} | Device: {tensor.device} | Dtype: {tensor.dtype}")
    else:
        print(f"{name:30s} | Type: {type(tensor)} | Value: {tensor}")


def test_complete_pipeline():
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®æµæ°´çº¿"""
    print("=" * 80)
    print("LightDiffGS å®Œæ•´æµç¨‹å¼ é‡ç»´åº¦æµ‹è¯•")
    print("=" * 80)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # ========================================
    # 1. è¾“å…¥æ•°æ®ç»´åº¦
    # ========================================
    print("1. è¾“å…¥æ•°æ®ç»´åº¦")
    print("-" * 40)
    
    caption_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1/texts/captions.txt"
    image_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step1/images"

    dataset = MultiModalDataset(caption_file=caption_path, image_dir=image_path)
    print_tensor_info("æ•°æ®é›†æ ·æœ¬æ•°é‡", len(dataset))
    
    # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬æ¥æŸ¥çœ‹åŸå§‹æ•°æ®æ ¼å¼
    sample_data = dataset[0]
    sample_text, sample_image = sample_data['text'], sample_data['image']
    print_tensor_info("åŸå§‹æ–‡æœ¬è¾“å…¥", sample_text)
    print_tensor_info("åŸå§‹å›¾åƒè¾“å…¥", sample_image)

    print()
    
    # ========================================
    # 2. ç¼–ç å™¨è¾“å‡ºç»´åº¦
    # ========================================
    print("2. ç¼–ç å™¨è¾“å‡ºç»´åº¦")
    print("-" * 40)
    
    # å®ä¾‹åŒ–ç¼–ç å™¨
    text_encoder = TextEncoder().to(device)
    image_encoder = ImageEncoder().to(device)

    # ä½¿ç”¨çœŸå®æ•°æ®
    text_features = text_encoder(sample_text)
    
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])
    sample_image_tensor = transform(sample_image)
    image_features = image_encoder(sample_image_tensor.unsqueeze(0).to(device))


    print_tensor_info("æ–‡æœ¬ç‰¹å¾", text_features)
    print_tensor_info("å›¾åƒç‰¹å¾", image_features)
    
    # å¤šæ¨¡æ€èåˆç¼–ç å™¨
    mm_encoder = MultiModalEncoder(
        text_encoder=text_encoder,
        image_encoder=image_encoder,
        fusion_outchannels=768,
        fusion_outfeatures=512
    ).to(device)
    
    dataset = MultiModalDataset(caption_file=caption_path, image_dir=image_path)
    fused_loader = MultiModalDataLoader(dataset, mm_encoder, device=device)
    
    print_tensor_info("èåˆç‰¹å¾æ•°æ®é›†å¤§å°", len(fused_loader))
    
    # å–ç¬¬ä¸€æ¡æ ·æœ¬
    fused_feature = fused_loader[0]
    print_tensor_info("èåˆç‰¹å¾ (åŸå§‹)", fused_feature)
    
    # æ·»åŠ batchç»´åº¦ï¼Œä¿æŒä¸è®­ç»ƒæ—¶ä¸€è‡´
    if fused_feature.ndim == 3:
        fused_feature = fused_feature.unsqueeze(0)
    fused_feature = fused_feature.to(device)
    print_tensor_info("èåˆç‰¹å¾ (4D)", fused_feature)
    print()
    
    # ========================================
    # 3. VAE ç¼–ç å™¨ç»´åº¦
    # ========================================
    print("3. VAE ç¼–ç å™¨ç»´åº¦")
    print("-" * 40)
    
    # å®ä¾‹åŒ– GaussianEncoderï¼Œå‚æ•°ä¸å…¶ä»–æµ‹è¯•æ–‡ä»¶ä¿æŒä¸€è‡´
    vae_encoder = GaussianEncoder(
        in_channels=768,  # ä½¿ç”¨æ­£ç¡®çš„é€šé“æ•°
        latent_dim=512,
        hidden_dims=[16, 24, 40],
        kl_std=1.0,
        beta=4,
        gamma=10.0,
        max_capacity=25,
        capacity_max_iteration=1e5,
        loss_type='B'
    ).to(device)
    
    # è¿è¡ŒVAEç¼–ç å™¨
    vae_outputs = vae_encoder(fused_feature)
    recon_x, input_x, mu, logvar, z = vae_outputs
    
    print_tensor_info("VAEé‡æ„è¾“å‡º", recon_x)
    print_tensor_info("VAEåŸå§‹è¾“å…¥", input_x)
    print_tensor_info("VAEå‡å€¼", mu)
    print_tensor_info("VAEå¯¹æ•°æ–¹å·®", logvar)
    print_tensor_info("VAEæ½œåœ¨å‘é‡", z)
    
    # éªŒè¯ç»´åº¦ä¸€è‡´æ€§
    assert recon_x.shape == input_x.shape, f"é‡æ„è¾“å‡ºä¸è¾“å…¥å½¢çŠ¶ä¸åŒ¹é…: {recon_x.shape} vs {input_x.shape}"
    assert mu.shape == logvar.shape == z.shape, f"æ½œåœ¨å‘é‡ç»´åº¦ä¸åŒ¹é…: {mu.shape}, {logvar.shape}, {z.shape}"
    
    print("âœ… VAEç¼–ç å™¨ç»´åº¦éªŒè¯é€šè¿‡")
    print()
    
    # ========================================
    # 4. VAE è§£ç å™¨ç»´åº¦
    # ========================================
    print("4. VAE è§£ç å™¨ç»´åº¦")
    print("-" * 40)
    
    decoder = TriplaneDecoder(
        latent_dim=512, 
        grid_size=(64, 64), 
        hidden_dim=40
    ).to(device)
    
    gau_pf, gau_cf, gau_tf = decoder(z)
    
    print_tensor_info("VAEè§£ç  - ä½ç½®ç‰¹å¾", gau_pf)
    print_tensor_info("VAEè§£ç  - é¢œè‰²ç‰¹å¾", gau_cf) 
    print_tensor_info("VAEè§£ç  - å˜æ¢ç‰¹å¾", gau_tf)

    expected_shapes = {
        'gau_pf': (1, 1, 64, 64),    # ä½ç½®ç‰¹å¾ï¼š[batch, 1, 64, 64]
        'gau_cf': (1, 48, 64, 64),   # é¢œè‰²ç‰¹å¾ï¼š[batch, 48, 64, 64]
        'gau_tf': (1, 7, 64, 64)     # å˜æ¢ç‰¹å¾ï¼š[batch, 7, 64, 64]
    }
    
    actual_shapes = {
        'gau_pf': gau_pf.shape,
        'gau_cf': gau_cf.shape,
        'gau_tf': gau_tf.shape
    }
    
    for name, expected in expected_shapes.items():
        actual = actual_shapes[name]
        assert actual == expected, f"{name} å½¢çŠ¶ä¸åŒ¹é…: æœŸæœ› {expected}, å®é™… {actual}"
    
    print("âœ… TriplaneDecoder ç»´åº¦éªŒè¯é€šè¿‡")

    print()
    
    # ========================================
    # 5. é«˜æ–¯æ¨¡å‹ç»´åº¦
    # ========================================
    print("5. é«˜æ–¯æ¨¡å‹ç»´åº¦")
    print("-" * 40)

    # æ„é€  specs å­—å…¸
    specs = {
        "GaussianModelSpecs": {
            "hidden_dims": [16, 24, 40],
            "latent_dim": 512,              
            "fusion_outfeatures": 512,      
            "fusion_outchannels": 768,        
            "skip_connection": True,
            "tanh_act": False,
            "pn_hidden_dim": 256            
        }
    }

    gaussian_model = GaussianModel(specs).to(device)
    print("âœ… GaussianModel åˆ›å»ºæˆåŠŸ")

    # ğŸ”§ åŠ è½½çœŸå®çš„é«˜æ–¯å’Œå ç”¨æ•°æ®
    print("åŠ è½½çœŸå®çš„é«˜æ–¯å’Œå ç”¨æ•°æ®:")
    gaussian_data_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step4/0/gaussian.npy"
    occ_data_path = "/home/andywu/Documents/dongjun/LightDiffGS/process_data/step4/0/occ.npy"

    try:
        # åŠ è½½çœŸå®é«˜æ–¯æ•°æ®
        real_gaussian_data = np.load(gaussian_data_path)
        real_gaussian_data = torch.tensor(real_gaussian_data).float().to(device)
        
        if real_gaussian_data.ndim == 2:
            real_gaussian_data = real_gaussian_data.unsqueeze(0)
        
        print_tensor_info("çœŸå®é«˜æ–¯æ•°æ®", real_gaussian_data)
        
        # æå–é«˜æ–¯åæ ‡å’Œç‰¹å¾
        gaussian_xyz = real_gaussian_data[:, :, :3]
        print_tensor_info("çœŸå®é«˜æ–¯åæ ‡", gaussian_xyz)
        
        # åˆ†æé«˜æ–¯æ•°æ®ç»“æ„
        print(f"é«˜æ–¯æ•°æ®ç‰¹å¾ç»´åº¦: {real_gaussian_data.shape[-1]}")
        if real_gaussian_data.shape[-1] >= 59:
            gt_xyz = real_gaussian_data[:, :, :3]
            gt_colors = real_gaussian_data[:, :, 3:51]  # 48ç»´é¢œè‰²
            gt_opacity = real_gaussian_data[:, :, 51:52]
            gt_scale = real_gaussian_data[:, :, 52:55]
            gt_rotation = real_gaussian_data[:, :, 55:59]
            
            print_tensor_info("GT - 3Dåæ ‡", gt_xyz)
            print_tensor_info("GT - é¢œè‰²ç‰¹å¾", gt_colors)
            print_tensor_info("GT - ä¸é€æ˜åº¦", gt_opacity)
            print_tensor_info("GT - ç¼©æ”¾å‚æ•°", gt_scale)
            print_tensor_info("GT - æ—‹è½¬å‚æ•°", gt_rotation)
        
        # åŠ è½½çœŸå®å ç”¨æ•°æ®
        real_occ_data = np.load(occ_data_path)
        real_occ_data = torch.tensor(real_occ_data).float().to(device)
        
        if real_occ_data.ndim == 2:
            real_occ_data = real_occ_data.unsqueeze(0)
        
        print_tensor_info("çœŸå®å ç”¨æ•°æ®", real_occ_data)
        
        # æå–å ç”¨åæ ‡å’Œå€¼
        if real_occ_data.shape[-1] >= 3:
            occ_xyz = real_occ_data[:, :, :3]
            print_tensor_info("çœŸå®å ç”¨åæ ‡", occ_xyz)
            
            if real_occ_data.shape[-1] >= 4:
                occ_values = real_occ_data[:, :, 3:]
                print_tensor_info("çœŸå®å ç”¨å€¼", occ_values)
        
        print("âœ… çœŸå®æ•°æ®åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
        print("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
        # æ¨¡æ‹Ÿæ•°æ®
        real_gaussian_data = torch.randn(1, 1000, 59).to(device)
        gaussian_xyz = real_gaussian_data[:, :, :3]
        real_occ_data = torch.randn(1, 10000, 4).to(device)
        occ_xyz = real_occ_data[:, :, :3]
        occ_values = real_occ_data[:, :, 3:]

    # ğŸ”§ æµ‹è¯•1: GaussianModel.forward() æ–¹æ³•ï¼ˆä¸éœ€è¦é¢å¤–å‚æ•°ï¼‰
    print("\næµ‹è¯• GaussianModel.forward() æ–¹æ³•:")
    try:
        # ä½¿ç”¨æ­£ç¡®çš„è¾“å…¥ï¼šåªéœ€è¦èåˆç‰¹å¾
        print_tensor_info("èåˆç‰¹å¾è¾“å…¥", fused_feature)  # [1, 768, 64, 64]
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¸ä¼ å…¥é«˜æ–¯å‚æ•°
        gau_pf_pred, gau_cf_pred, gau_tf_pred = gaussian_model(fused_feature)
        
        print_tensor_info("é¢„æµ‹ä½ç½®ç‰¹å¾", gau_pf_pred)
        print_tensor_info("é¢„æµ‹é¢œè‰²ç‰¹å¾", gau_cf_pred)
        print_tensor_info("é¢„æµ‹å˜æ¢ç‰¹å¾", gau_tf_pred)
        
        # éªŒè¯è¾“å‡ºç»´åº¦
        assert gau_pf_pred.shape == (1, 1, 64, 64), f"ä½ç½®ç‰¹å¾å½¢çŠ¶é”™è¯¯: {gau_pf_pred.shape}"
        assert gau_cf_pred.shape == (1, 48, 64, 64), f"é¢œè‰²ç‰¹å¾å½¢çŠ¶é”™è¯¯: {gau_cf_pred.shape}"
        assert gau_tf_pred.shape == (1, 7, 64, 64), f"å˜æ¢ç‰¹å¾å½¢çŠ¶é”™è¯¯: {gau_tf_pred.shape}"
        
        print("âœ… GaussianModel.forward() æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ GaussianModel.forward() é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\næµ‹è¯•ä½¿ç”¨é¢„æµ‹ä¸‰å¹³é¢ç‰¹å¾è¿›è¡Œé«˜æ–¯å‚æ•°é¢„æµ‹:")
    try:
        # åˆå¹¶ä¸‰å¹³é¢ç‰¹å¾
        predicted_plane_features = torch.cat([gau_pf_pred, gau_cf_pred, gau_tf_pred], dim=1)
        print_tensor_info("é¢„æµ‹çš„ä¸‰å¹³é¢ç‰¹å¾", predicted_plane_features) # åº”è¯¥æ˜¯ [1, 56, 64, 64]
        
        # ğŸ”§ é™åˆ¶æŸ¥è¯¢ç‚¹æ•°é‡
        max_points = 1000
        if gaussian_xyz.shape[1] > max_points:
            sample_indices = torch.randperm(gaussian_xyz.shape[1])[:max_points]
            sample_xyz = gaussian_xyz[:, sample_indices, :]
        else:
            sample_xyz = gaussian_xyz
        
        print_tensor_info("é‡‡æ ·æŸ¥è¯¢åæ ‡", sample_xyz)
        
        # ä½¿ç”¨é¢„æµ‹çš„ä¸‰å¹³é¢ç‰¹å¾è¿›è¡ŒæŸ¥è¯¢
        final_colors, final_transforms = gaussian_model.forward_with_plane_features(
            predicted_plane_features, sample_xyz
        )
        
        print_tensor_info("æœ€ç»ˆé¢„æµ‹é¢œè‰²", final_colors)
        print_tensor_info("æœ€ç»ˆé¢„æµ‹å˜æ¢", final_transforms)
        
        # å ç”¨é¢„æµ‹
        final_occupancy = gaussian_model.forward_with_plane_features_pf(
            predicted_plane_features, sample_xyz
        )
        
        print_tensor_info("æœ€ç»ˆé¢„æµ‹å ç”¨", final_occupancy)
        
        print("âœ… å®Œæ•´é¢„æµ‹æµç¨‹æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ å®Œæ•´é¢„æµ‹æµç¨‹é”™è¯¯: {e}")

    # ä¿®å¤ VAE æŸå¤±è®¡ç®—éƒ¨åˆ†ï¼š
    print("\næµ‹è¯• VAE æŸå¤±è®¡ç®—:")
    try:
        if hasattr(gaussian_model, 'get_vae_loss'):
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
            vae_loss_dict = gaussian_model.get_vae_loss(fused_feature, minibatch_weight=1.0)
            print_tensor_info("VAEæ€»æŸå¤±", vae_loss_dict['loss'])
            print_tensor_info("é‡æ„æŸå¤±", vae_loss_dict['Reconstruction_Loss'])
            print_tensor_info("KLæ•£åº¦æŸå¤±", vae_loss_dict['KLD'])
            print("âœ… VAEæŸå¤±è®¡ç®—æˆåŠŸ")
        else:
            # ğŸ”§ å¦‚æœæ²¡æœ‰get_vae_lossæ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨encoderçš„æŸå¤±å‡½æ•°
            print("ä½¿ç”¨ GaussianEncoder ç›´æ¥è®¡ç®—æŸå¤±...")
            vae_loss_dict = vae_encoder.loss_function(*vae_outputs, minibatch_weight=1.0)  # ğŸ”§ ä¿®å¤å‚æ•°å
            print_tensor_info("VAEæ€»æŸå¤±", vae_loss_dict['loss'])
            print_tensor_info("é‡æ„æŸå¤±", vae_loss_dict['Reconstruction_Loss'])
            print_tensor_info("KLæ•£åº¦æŸå¤±", vae_loss_dict['KLD'])
            print("âœ… VAEæŸå¤±è®¡ç®—æˆåŠŸ")
    except Exception as e:
        print(f"âŒ VAEæŸå¤±è®¡ç®—é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    # ä¿®å¤è°ƒè¯• ConvPointnetLite éƒ¨åˆ†ï¼š
    print("\nè°ƒè¯• ConvPointnetLite æœŸæœ›çš„è¾“å…¥ç»´åº¦:")
    try:
        pointnet = gaussian_model.pointnet
        print(f"ConvPointnetLite c_dim: {pointnet.c_dim}")
        print(f"ConvPointnetLite dim: {getattr(pointnet, 'dim', 3)}")  # ğŸ”§ ä½¿ç”¨getattré¿å…é”™è¯¯
        print(f"ConvPointnetLite hidden_dim: {getattr(pointnet, 'hidden_dim', 64)}")
        print(f"ConvPointnetLite plane_resolution: {getattr(pointnet, 'plane_resolution', 64)}")
        print(f"ConvPointnetLite plane_type: {getattr(pointnet, 'plane_type', ['xy', 'xz', 'yz'])}")
        
        # ğŸ”§ åˆ†æå¹³é¢ç‰¹å¾åˆ†é…
        actual_plane_channels = 56  # gau_pf(1) + gau_cf(48) + gau_tf(7) = 56
        num_planes = len(getattr(pointnet, 'plane_type', ['xy', 'xz', 'yz']))
        channels_per_plane = actual_plane_channels // num_planes
        remaining_channels = actual_plane_channels % num_planes
        
        print(f"å®é™…çš„å¹³é¢ç‰¹å¾é€šé“æ•°: {actual_plane_channels}")
        print(f"å¹³é¢æ•°é‡: {num_planes}")
        print(f"æ¯ä¸ªå¹³é¢åŸºç¡€é€šé“æ•°: {channels_per_plane}")
        print(f"ä½™æ•°é€šé“: {remaining_channels}")
        print(f"å¹³é¢é€šé“åˆ†é…: {[channels_per_plane + (1 if i < remaining_channels else 0) for i in range(num_planes)]}")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    # ğŸ”§ æµ‹è¯•4: æ½œåœ¨å‘é‡æå–
    print("\næµ‹è¯•æ½œåœ¨å‘é‡æå–:")
    try:
        if hasattr(gaussian_model, 'get_latent_vector'):
            latent_z = gaussian_model.get_latent_vector(fused_feature)
            print_tensor_info("æå–çš„æ½œåœ¨å‘é‡", latent_z)
        else:
            print("ä½¿ç”¨å·²æœ‰çš„æ½œåœ¨å‘é‡:", z.shape)
            latent_z = z
        
        # æµ‹è¯•ä»æ½œåœ¨å‘é‡è§£ç 
        if hasattr(gaussian_model, 'decode_from_latent'):
            decoded_pf, decoded_cf, decoded_tf = gaussian_model.decode_from_latent(latent_z)
            print_tensor_info("è§£ç ä½ç½®ç‰¹å¾", decoded_pf)
            print_tensor_info("è§£ç é¢œè‰²ç‰¹å¾", decoded_cf)
            print_tensor_info("è§£ç å˜æ¢ç‰¹å¾", decoded_tf)
            print("âœ… æ½œåœ¨å‘é‡æ“ä½œæˆåŠŸ")
        else:
            print("ä½¿ç”¨å·²æœ‰çš„è§£ç ç»“æœ")
    except Exception as e:
        print(f"âŒ æ½œåœ¨å‘é‡æ“ä½œé”™è¯¯: {e}")

    # ğŸ”§ æ€»ç»“
    print("\nğŸ¯ æµç¨‹æ€»ç»“:")
    print("=" * 50)
    print("âœ… 1. å¤šæ¨¡æ€è¾“å…¥ â†’ èåˆç‰¹å¾:", fused_feature.shape)
    print("âœ… 2. èåˆç‰¹å¾ â†’ VAEç¼–ç  â†’ æ½œåœ¨å‘é‡:", z.shape)
    print("âœ… 3. æ½œåœ¨å‘é‡ â†’ VAEè§£ç  â†’ ä¸‰å¹³é¢ç‰¹å¾:")
    print(f"   - ä½ç½®ç‰¹å¾: {gau_pf.shape}")
    print(f"   - é¢œè‰²ç‰¹å¾: {gau_cf.shape}")
    print(f"   - å˜æ¢ç‰¹å¾: {gau_tf.shape}")
    print("âœ… 4. GaussianModelå®Œæ•´å‰å‘ä¼ æ’­:", (gau_pf_pred.shape, gau_cf_pred.shape, gau_tf_pred.shape))
    
    if 'final_colors' in locals():
        print("âœ… 5. ä¸‰å¹³é¢ç‰¹å¾ + åæ ‡æŸ¥è¯¢ â†’ é¢„æµ‹:")
        print(f"   - é¢„æµ‹é¢œè‰²: {final_colors.shape}")
        print(f"   - é¢„æµ‹å˜æ¢: {final_transforms.shape}")
        if 'final_occupancy' in locals():
            print(f"   - é¢„æµ‹å ç”¨: {final_occupancy.shape}")
    
    print("=" * 50)
    print("âœ… æµ‹è¯•å®Œæˆï¼GaussianModel å·¥ä½œæ­£å¸¸")

if __name__ == "__main__":
    test_complete_pipeline()
